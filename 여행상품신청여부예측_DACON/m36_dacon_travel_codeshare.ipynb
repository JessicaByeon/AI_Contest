{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#1. data\n",
    "path = 'D:/study_data/_data/dacon_travel/'\n",
    "train_set = pd.read_csv(path + 'train.csv', index_col=0)\n",
    "test_set = pd.read_csv(path + 'test.csv', index_col=0)\n",
    "\n",
    "# print(train_set)\n",
    "# print(train_set.shape) # (1955, 19)\n",
    "# print(train_set.columns)\n",
    "# Index(['Age', 'TypeofContact', 'CityTier', 'DurationOfPitch', 'Occupation',\n",
    "#        'Gender', 'NumberOfPersonVisiting', 'NumberOfFollowups',\n",
    "#        'ProductPitched', 'PreferredPropertyStar', 'MaritalStatus',\n",
    "#        'NumberOfTrips', 'Passport', 'PitchSatisfactionScore', 'OwnCar',\n",
    "#        'NumberOfChildrenVisiting', 'Designation', 'MonthlyIncome',\n",
    "#        'ProdTaken'],\n",
    "#       dtype='object')\n",
    "\n",
    "# print(train_set.info())\n",
    "# print(train_set.describe())\n",
    "\n",
    "# print(test_set)\n",
    "# print(test_set.shape) # (2933, 18)\n",
    "\n",
    "# 결측치 확인\n",
    "# print(train_set.isnull().sum())\n",
    "# print(test_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 불러와서 데이터의 상세내용을 확인한다. info, describe, features 및 결측치를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "# DurationOfPitch 결측치 0으로 채우기\n",
    "train_set['DurationOfPitch'] = train_set['DurationOfPitch'].fillna(0)\n",
    "test_set['DurationOfPitch'] = test_set['DurationOfPitch'].fillna(0)\n",
    "\n",
    "# TypeofContact 결측치 \"Self Enquiry\"로 채우기\n",
    "train_set['TypeofContact'] = train_set['TypeofContact'].fillna(\"Self Enquiry\")\n",
    "test_set['TypeofContact'] = test_set['TypeofContact'].fillna(\"Self Enquiry\")\n",
    "\n",
    "# Gender의 Fe male -> Female 로 변경\n",
    "# print(train_set['Gender'].value_counts())\n",
    "# train_set['Gender'] = train_set.replace({'Gender' : 'Fe Male'}, 'Female') # df = df.replace({'열 이름' : 기존 값}, 변경 값) \n",
    "# test_set['Gender'] = test_set.replace({'Gender' : 'Fe Male'}, 'Female') # ValueError: Columns must be same length as key [원인찾기]\n",
    "train_set['Gender'] = train_set['Gender'].str.replace('Fe Male', 'Female')\n",
    "test_set['Gender'] = train_set['Gender'].str.replace('Fe Male', 'Female')\n",
    "\n",
    "# MonthlyIncome (Designation별 평균으로 변경)\n",
    "train_set['MonthlyIncome'] = train_set['MonthlyIncome'].fillna(train_set.groupby('Designation')['MonthlyIncome'].transform('median'))\n",
    "test_set['MonthlyIncome'] = test_set['MonthlyIncome'].fillna(test_set.groupby('Designation')['MonthlyIncome'].transform('median'))\n",
    "\n",
    "# Occupation / freelancer -> 최빈값(Salaried)으로 변경\n",
    "# print(train_set['Occupation'].value_counts())\n",
    "# train_set['Occupation'] = train_set['Occupation'].str.replace('Free Lancer', train_set['Occupation'].mode())\n",
    "train_set['Occupation'] = train_set['Occupation'].str.replace('Free Lancer', 'Salaried')\n",
    "test_set['Occupation'] = test_set['Occupation'].str.replace('Free Lancer', 'Salaried')\n",
    "\n",
    "# MarialStatus의 Unmarried, Divorced -> Single로 변경 등 여러가지 경우의 수로 맵핑 진행\n",
    "# print(train_set['MaritalStatus'].value_counts())\n",
    "# Married      949\n",
    "# Divorced     375\n",
    "# Single       349\n",
    "# Unmarried    282\n",
    "# Name: MaritalStatus, dtype: int64\n",
    "# train_set['MaritalStatus'] = train_set['MaritalStatus'].str.replace('Divorced', 'Single')\n",
    "# test_set['MaritalStatus'] = test_set['MaritalStatus'].str.replace('Divorced', 'Single')\n",
    "# train_set['MaritalStatus'] = train_set['MaritalStatus'].str.replace('Unmarried', 'Single')\n",
    "# test_set['MaritalStatus'] = test_set['MaritalStatus'].str.replace('Unmarried', 'Single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 확인 후 컬럼별로 적합하다고 생각되는 전처리를 진행한다.\n",
    "\n",
    "마지막 MarialStatus의 경우 다양한 방법으로 맵핑을 진행해보았으나 그대로 두는 것이 가장 성능이 좋은 것을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['NumberOfFollowups'].fillna(train_set.groupby('NumberOfChildrenVisiting')['NumberOfFollowups'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfFollowups'].fillna(test_set.groupby('NumberOfChildrenVisiting')['NumberOfFollowups'].transform('mean'), inplace=True)\n",
    "\n",
    "train_set['PreferredPropertyStar'].fillna(train_set.groupby('Occupation')['PreferredPropertyStar'].transform('mean'), inplace=True)\n",
    "test_set['PreferredPropertyStar'].fillna(test_set.groupby('Occupation')['PreferredPropertyStar'].transform('mean'), inplace=True)\n",
    "\n",
    "train_set['NumberOfTrips'].fillna(train_set.groupby('DurationOfPitch')['NumberOfTrips'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfTrips'].fillna(test_set.groupby('DurationOfPitch')['NumberOfTrips'].transform('mean'), inplace=True)\n",
    "\n",
    "train_set['NumberOfChildrenVisiting'].fillna(train_set.groupby('MaritalStatus')['NumberOfChildrenVisiting'].transform('mean'), inplace=True)\n",
    "test_set['NumberOfChildrenVisiting'].fillna(test_set.groupby('MaritalStatus')['NumberOfChildrenVisiting'].transform('mean'), inplace=True)\n",
    "\n",
    "# train_set['AgeBand'] = pd.cut(train_set['Age'], 5)\n",
    "# 임의로 5개 그룹을 지정\n",
    "# print(train_set['AgeBand'])\n",
    "# [(17.957, 26.6] < (26.6, 35.2] < (35.2, 43.8] <\n",
    "# (43.8, 52.4] < (52.4, 61.0]]\n",
    "combine = [train_set, test_set]\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 26.6, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 26.6) & (dataset['Age'] <= 35.2), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 35.2) & (dataset['Age'] <= 43.8), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 43.8) & (dataset['Age'] <= 52.4), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 52.4, 'Age'] = 4\n",
    "# train_set = train_set.drop(['AgeBand'], axis=1)\n",
    "\n",
    "'''\n",
    "# combine = [train_set, test_set] # 10/20대, 30/40대, 50/60대로 나누기\n",
    "# for dataset in combine:    \n",
    "#     dataset.loc[ dataset['Age'] <= 29, 'Age'] = 0\n",
    "#     dataset.loc[(dataset['Age'] > 29) & (dataset['Age'] <= 39), 'Age'] = 1\n",
    "#     dataset.loc[(dataset['Age'] > 39) & (dataset['Age'] <= 49), 'Age'] = 2\n",
    "#     dataset.loc[ dataset['Age'] > 49, 'Age'] = 3\n",
    "\n",
    "\n",
    "# combine = [train_set, test_set] # 10/20/30, 40, 50/60대로 나누기\n",
    "# for dataset in combine:    \n",
    "#     dataset.loc[ dataset['Age'] <= 39, 'Age'] = 0\n",
    "#     dataset.loc[(dataset['Age'] > 39) & (dataset['Age'] <= 49), 'Age'] = 1\n",
    "#     # dataset.loc[(dataset['Age'] > 49) & (dataset['Age'] <= 49), 'Age'] = 2\n",
    "#     dataset.loc[ dataset['Age'] > 49, 'Age'] = 2\n",
    "\n",
    "# combine = [train_set, test_set] # 10/20, 30, 40, 50, 60대로 나누기\n",
    "# for dataset in combine:    \n",
    "#     dataset.loc[ dataset['Age'] <= 29, 'Age'] = 0\n",
    "#     dataset.loc[(dataset['Age'] > 29) & (dataset['Age'] <= 39), 'Age'] = 1\n",
    "#     dataset.loc[(dataset['Age'] > 39) & (dataset['Age'] <= 49), 'Age'] = 2\n",
    "#     dataset.loc[(dataset['Age'] > 49) & (dataset['Age'] <= 59), 'Age'] = 3\n",
    "#     dataset.loc[ dataset['Age'] > 59, 'Age'] = 4\n",
    "\n",
    "combine = [train_set, test_set] # 10/20, 30, 40, 50/60대로 나누기\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 29, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 29) & (dataset['Age'] <= 39), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 39) & (dataset['Age'] <= 49), 'Age'] = 3\n",
    "    # dataset.loc[(dataset['Age'] > 49) & (dataset['Age'] <= 59), 'Age'] = 4\n",
    "    dataset.loc[ dataset['Age'] > 49, 'Age'] = 4\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나이의 경우 범주화를 여러가지로 한 결과 순차적으로 5그룹으로 범주화시킨 경우가 가장 성능이 좋음을 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_set['TypeofContact'] = le.fit_transform(train_set['TypeofContact'])\n",
    "test_set['TypeofContact'] = le.fit_transform(test_set['TypeofContact'])\n",
    "train_set['Occupation'] = le.fit_transform(train_set['Occupation'])\n",
    "test_set['Occupation'] = le.fit_transform(test_set['Occupation'])\n",
    "train_set['Gender'] = le.fit_transform(train_set['Gender'])\n",
    "test_set['Gender'] = le.fit_transform(test_set['Gender'])\n",
    "train_set['ProductPitched'] = le.fit_transform(train_set['ProductPitched'])\n",
    "test_set['ProductPitched'] = le.fit_transform(test_set['ProductPitched'])\n",
    "train_set['MaritalStatus'] = le.fit_transform(train_set['MaritalStatus'])\n",
    "test_set['MaritalStatus'] = le.fit_transform(test_set['MaritalStatus'])\n",
    "train_set['Designation'] = le.fit_transform(train_set['Designation'])\n",
    "test_set['Designation'] = le.fit_transform(test_set['Designation'])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "# scaler = MaxAbsScaler()\n",
    "# scaler = RobustScaler()\n",
    "\n",
    "train_set[['Age', 'DurationOfPitch']] = scaler.fit_transform(train_set[['Age', 'DurationOfPitch']])\n",
    "test_set[['Age', 'DurationOfPitch']] = scaler.transform(test_set[['Age', 'DurationOfPitch']])\n",
    "\n",
    "\n",
    "# 모든 데이터 처리 완료 확인\n",
    "# print(train_set.info())\n",
    "\n",
    "train_set = train_set.drop(['NumberOfChildrenVisiting','NumberOfPersonVisiting',\n",
    "                          'OwnCar', \n",
    "                          'MonthlyIncome', \n",
    "                          'NumberOfFollowups', \n",
    "                          'NumberOfTrips',\n",
    "                          'NumberOfFollowups',\n",
    "                          ], axis=1)\n",
    "test_set = test_set.drop(['NumberOfChildrenVisiting','NumberOfPersonVisiting',\n",
    "                          'OwnCar', \n",
    "                          'MonthlyIncome', \n",
    "                          'NumberOfFollowups', \n",
    "                          'NumberOfTrips',\n",
    "                          'NumberOfFollowups',\n",
    "                          ], axis=1)\n",
    "\n",
    "\n",
    "x = train_set.drop(['ProdTaken'],axis=1) #axis는 컬럼 \n",
    "# print(x) \n",
    "\n",
    "y = train_set['ProdTaken']\n",
    "# print(y.shape)\n",
    "\n",
    "# print(train_set.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주형 데이터를 레이블 인코딩해주고, 수치의 편차가 큰 데이터에 한해 스케일링을 진행하여 모든 데이터의 전처리를 완료했다.\n",
    "\n",
    "상관관계가 적거나 포함 시에 성능이 떨어지는 컬럼을 삭제했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  x, y, train_size=0.93, shuffle=True, random_state=1234, stratify=y)\n",
    "\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=666)\n",
    "\n",
    "\n",
    "# 최적의 매개변수\n",
    "parameters = {'n_estimators' : [1000],\n",
    "              'learning_rate' : [0.01],\n",
    "              'depth': [15],\n",
    "              'l2_leaf_reg' : [1],\n",
    "              'model_size_reg' : [0],\n",
    "              'od_pval' : [0],\n",
    "}\n",
    "\n",
    "# 2. model\n",
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(random_state=123, verbose=False, n_estimators=500)\n",
    "model = RandomizedSearchCV(cat, parameters, cv=kfold, n_jobs=-1)\n",
    "\n",
    "#3. train, predict\n",
    "model.fit(x_train, y_train)   \n",
    "y_predict = model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "results = accuracy_score(y_test, y_predict)\n",
    "print('최적의 매개변수 : ', model.best_params_)\n",
    "print('최상의 점수 : ', model.best_score_)\n",
    "print('acc :', results)\n",
    "# print('걸린 시간 :', end_time)\n",
    "\n",
    "\n",
    "#4. submission\n",
    "y_summit = model.predict(test_set)\n",
    "submission = pd.read_csv(path + 'sample_submission.csv')\n",
    "submission['ProdTaken'] = y_summit\n",
    "submission.to_csv(path + 'sample_submission_50_02.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set/test set을 나누어주고, StratifiedKFold 를 진행하여 교차검증을 진행하여 데이터를 최종적으로 준비한다.\n",
    "\n",
    "캣부스트 모델에 랜덤서치를 이용하여 모델을 만들었고, 별도로 찾은 최적의 매개변수를 모델의 파라미터로 활용한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf282gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3139ac83b26172bd642cd137c7507a36a300db7fe5bc98861af4fe61734cb9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
